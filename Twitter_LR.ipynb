{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import nltk\n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "pd.options.display.max_columns=100\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "train_df = pd.read_csv('./train.csv')\n",
    "test_df =  pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in urð±!!! ðððð",
       "ð¦ð¦ð¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[2/2] huge fan fare and big talking before they leave. chaos and pay disputes when they get there. #allshowandnogo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>@user camping tomorrow @user @user @user @user @user @user @user dannyâ¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>the next school year is the year for exams.ð¯ can't think about that ð­ #school #exams   #hate #imagine #actorslife #revolutionschool #girl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>we won!!! love the land!!! #allin #cavs #champions #cleveland #clevelandcavaliers  â¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user welcome here !  i'm   it's so #gr8 !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label  \\\n",
       "0  1   0       \n",
       "1  2   0       \n",
       "2  3   0       \n",
       "3  4   0       \n",
       "4  5   0       \n",
       "5  6   0       \n",
       "6  7   0       \n",
       "7  8   0       \n",
       "8  9   0       \n",
       "9  10  0       \n",
       "\n",
       "                                                                                                                                             tweet  \n",
       "0   @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run                                           \n",
       "1  @user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked                       \n",
       "2    bihday your majesty                                                                                                                            \n",
       "3  #model   i love u take with u all the time in urð±!!! ðððð\n",
       "ð¦ð¦ð¦                                                             \n",
       "4   factsguide: society now    #motivation                                                                                                          \n",
       "5  [2/2] huge fan fare and big talking before they leave. chaos and pay disputes when they get there. #allshowandnogo                               \n",
       "6   @user camping tomorrow @user @user @user @user @user @user @user dannyâ¦                                                                       \n",
       "7  the next school year is the year for exams.ð¯ can't think about that ð­ #school #exams   #hate #imagine #actorslife #revolutionschool #girl  \n",
       "8  we won!!! love the land!!! #allin #cavs #champions #cleveland #clevelandcavaliers  â¦                                                           \n",
       "9   @user @user welcome here !  i'm   it's so #gr8 !                                                                                                "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29720\n",
      "2242\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "df_majority = train_df[train_df['label'] == 0]\n",
    "df_minority = train_df[train_df['label'] == 1]\n",
    "df_minority_upsampeled = resample(df_minority,\n",
    "                                  replace = True,\n",
    "                                  n_samples = 5000,\n",
    "                                  random_state = 101)\n",
    "df_upsampled = pd.concat([df_majority,df_minority_upsampeled])\n",
    "print(len(df_majority))\n",
    "print(len(df_minority))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\c.m.abhishek\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "df = df_upsampled.append(test_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49139</th>\n",
       "      <td>49140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i am thankful for children. #thankful #positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49140</th>\n",
       "      <td>49141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>liverpool â¤ï¸ð¬ð§ #walk #liverpool #starbucks #avidaeboa   #passeio #chocolate #deliciousâ¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49141</th>\n",
       "      <td>49142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#bakersfield   rooster simulation: i want to climb the vast expanse of mountains. it reached the leakage coc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49142</th>\n",
       "      <td>49143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>por do sol ó¾â¤ï¸#instagood #beautiful   #instadaily #instalike #instamood #amazing #bestoftheday #cool...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49143</th>\n",
       "      <td>49144</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@user hell yeah what a great surprise for your present enjoy this picture of me   #bihday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49144</th>\n",
       "      <td>49145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>when ur the joke ur defensive towards everythingð¯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49145</th>\n",
       "      <td>49146</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#enjoying the #evening #sun in my #bedroom â¨   #cozy evening ð #homesweethome #allwhiteâ¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49146</th>\n",
       "      <td>49147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tonight on @user from 9pm gmt  you can here a special early play of a new song from the upcoming album!  !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49147</th>\n",
       "      <td>49148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>today is a good day for excercise #imready #sofuckenready #letsgo #comeon #letsgetsta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49148</th>\n",
       "      <td>49149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>good night with a tea and music âï¸ððð» #billy #music #tea #mug #tokiohotelmug #tokiohotel  â¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49149</th>\n",
       "      <td>49150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>loving lifeðºð¸âï¸ð  #createyourfuture   #lifestyle #holiday #la @ hyatt regency long beach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49150</th>\n",
       "      <td>49151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>black professor demonizes, proposes nazi style confiscation of \"white\" assets; like 1930's germany  #breaking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49151</th>\n",
       "      <td>49152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>learn how to think positive.  #positive   #instagram #instagood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49152</th>\n",
       "      <td>49153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>we love the pretty, happy and fresh you! #teenilicious #fixdermateen #generationz #pretty   #fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49153</th>\n",
       "      <td>49154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2_damn_tuff-ruff_muff__techno_city-(ng005)-web-1997-ukhx_int . #web   hardcore #1gabba #vk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49154</th>\n",
       "      <td>49155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thought factory: left-right polarisation! #trump #uselections2016 #leadership #politics  #brexit #blm &amp;gt;3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49155</th>\n",
       "      <td>49156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>feeling like a mermaid ð #hairflip #neverready #formal #wedding #gown #dresses #mermaid  â¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49156</th>\n",
       "      <td>49157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#hillary #campaigned today in #ohio((omg)) &amp;amp; used words like \"assets&amp;amp;liability\" never once did #clinton say thee(word) #radicalization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49157</th>\n",
       "      <td>49158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>happy, at work conference: right mindset leads to culture-of-development organizations    #work #mindset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49158</th>\n",
       "      <td>49159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my   song \"so glad\" free download!  #shoegaze #newmusic #newsong</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label  \\\n",
       "49139  49140 NaN      \n",
       "49140  49141 NaN      \n",
       "49141  49142 NaN      \n",
       "49142  49143 NaN      \n",
       "49143  49144 NaN      \n",
       "49144  49145 NaN      \n",
       "49145  49146 NaN      \n",
       "49146  49147 NaN      \n",
       "49147  49148 NaN      \n",
       "49148  49149 NaN      \n",
       "49149  49150 NaN      \n",
       "49150  49151 NaN      \n",
       "49151  49152 NaN      \n",
       "49152  49153 NaN      \n",
       "49153  49154 NaN      \n",
       "49154  49155 NaN      \n",
       "49155  49156 NaN      \n",
       "49156  49157 NaN      \n",
       "49157  49158 NaN      \n",
       "49158  49159 NaN      \n",
       "\n",
       "                                                                                                                                                   tweet  \n",
       "49139  i am thankful for children. #thankful #positive                                                                                                    \n",
       "49140  liverpool â¤ï¸ð¬ð§ #walk #liverpool #starbucks #avidaeboa   #passeio #chocolate #deliciousâ¦                                                \n",
       "49141  #bakersfield   rooster simulation: i want to climb the vast expanse of mountains. it reached the leakage coc                                       \n",
       "49142  por do sol ó¾â¤ï¸#instagood #beautiful   #instadaily #instalike #instamood #amazing #bestoftheday #cool...                                     \n",
       "49143  @user hell yeah what a great surprise for your present enjoy this picture of me   #bihday                                                          \n",
       "49144  when ur the joke ur defensive towards everythingð¯                                                                                               \n",
       "49145  #enjoying the #evening #sun in my #bedroom â¨   #cozy evening ð #homesweethome #allwhiteâ¦                                                    \n",
       "49146  tonight on @user from 9pm gmt  you can here a special early play of a new song from the upcoming album!  !                                         \n",
       "49147  today is a good day for excercise #imready #sofuckenready #letsgo #comeon #letsgetsta                                                              \n",
       "49148  good night with a tea and music âï¸ððð» #billy #music #tea #mug #tokiohotelmug #tokiohotel  â¦                                         \n",
       "49149  loving lifeðºð¸âï¸ð  #createyourfuture   #lifestyle #holiday #la @ hyatt regency long beach                                              \n",
       "49150  black professor demonizes, proposes nazi style confiscation of \"white\" assets; like 1930's germany  #breaking                                      \n",
       "49151  learn how to think positive.  #positive   #instagram #instagood                                                                                    \n",
       "49152  we love the pretty, happy and fresh you! #teenilicious #fixdermateen #generationz #pretty   #fresh                                                 \n",
       "49153  2_damn_tuff-ruff_muff__techno_city-(ng005)-web-1997-ukhx_int . #web   hardcore #1gabba #vk                                                         \n",
       "49154  thought factory: left-right polarisation! #trump #uselections2016 #leadership #politics  #brexit #blm &gt;3                                        \n",
       "49155  feeling like a mermaid ð #hairflip #neverready #formal #wedding #gown #dresses #mermaid  â¦                                                    \n",
       "49156  #hillary #campaigned today in #ohio((omg)) &amp; used words like \"assets&amp;liability\" never once did #clinton say thee(word) #radicalization     \n",
       "49157  happy, at work conference: right mindset leads to culture-of-development organizations    #work #mindset                                           \n",
       "49158  my   song \"so glad\" free download!  #shoegaze #newmusic #newsong                                                                                   "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop_duplicates(inplace = True)\n",
    "df['tweet'] = df['tweet'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_usrtyp(sent):\n",
    "    r = re.findall(r'@\\w+',sent)\n",
    "    text = sent\n",
    "    for i in r:\n",
    "        text = re.sub(i,'',sent)\n",
    "    return text\n",
    "\n",
    "df['tweet'] = df['tweet'].apply(lambda x:remove_usrtyp(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing the html tags\n",
    "import html\n",
    "df['tweet'] = df['tweet'].apply(lambda x:html.unescape(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet'] = df['tweet'].str.replace(\"[#]\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "slng_dict = pd.read_csv('./slang_dict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# slng_dict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "slng_words = slng_dict['word'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slang_word_conv(sent):\n",
    "    tokens = sent.split()\n",
    "    new_sent = []\n",
    "    for w in tokens:\n",
    "        if w.upper() in slng_words:\n",
    "            new_sent.append(slng_dict.loc[slng_dict['word'] == w.upper(),'acronym'].iloc[0])\n",
    "        else:\n",
    "            new_sent.append(w)\n",
    "        \n",
    "    sent = ' '.join([w for w in new_sent]) \n",
    "    return sent\n",
    "            \n",
    "df['tweet_slang_conv'] = df['tweet'].apply(lambda x:slang_word_conv(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet_conv'] = df['tweet_slang_conv'].str.replace(\"[^a-zA-Z]\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = pd.Series(' '.join(df['tweet_conv']).split()).value_counts()[-10:]\n",
    "freq = list(freq.index)\n",
    "df['tweet_conv'] = df['tweet_conv'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet_word_list'] = df['tweet_conv'].apply(lambda x : x.split())\n",
    "df['tweet_word_list'] = df['tweet_word_list'].apply(lambda x:[w.lower() for w in x if len(w)>=3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lem = WordNetLemmatizer()\n",
    "df['tweet_word_list'] = df['tweet_word_list'].apply(lambda x:[lem.lemmatize(w)for w in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet_word_conv'] = df['tweet_word_list'].apply(lambda x: ' '.join([w for w in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_df = df[df['label'] == 1]['tweet_word_conv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# bow_vectorizer = CountVectorizer(max_df=0.90, min_df=2, max_features=10000,stop_words='english')\n",
    "bow_vectorizer = CountVectorizer(stop_words='english',ngram_range=(1, 5))\n",
    "# bag-of-words feature matrix\n",
    "bow = bow_vectorizer.fit_transform(df['tweet_word_conv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score:0.9124365482233502\n",
      "Confusion Matrix\n",
      "[[8702  170]\n",
      " [ 106 1438]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "train_bow = bow[:34720,:]\n",
    "test_bow = bow[34720:,:]\n",
    "\n",
    "# splitting data into training and validation set\n",
    "xtrain_bow, xvalid_bow, ytrain, yvalid = train_test_split(train_bow, df_upsampled['label'], random_state=42, test_size=0.3)\n",
    "\n",
    "lreg = LogisticRegression()\n",
    "lreg.fit(xtrain_bow, ytrain) # training the model\n",
    "\n",
    "prediction = lreg.predict_proba(xvalid_bow) # predicting on the validation set\n",
    "prediction_int = prediction[:,1] >= 0.2 # if prediction is greater than or equal to 0.2 than 1 else 0\n",
    "prediction_int = prediction_int.astype(np.int)\n",
    "\n",
    "f1 = f1_score(yvalid, prediction_int) # calculating f1 score\n",
    "print('F1-Score:'+str(f1))\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(yvalid, prediction_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = lreg.predict_proba(test_bow)\n",
    "test_pred_int = test_pred[:,1] >= 0.2\n",
    "test_pred_int = test_pred_int.astype(np.int)\n",
    "test_df['label'] = test_pred_int\n",
    "submission = test_df[['id','label']]\n",
    "submission.to_csv('sub_lreg_tsa1-git.csv', index=False) # writing data to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
